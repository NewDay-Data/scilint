# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/scilint.ipynb.

# %% auto 0
__all__ = ['run_nbqa_cmd', 'tidy', 'scilint_tidy', 'get_func_defs', 'count_func_calls', 'replace_ipython_magics', 'safe_div',
           'get_cell_code', 'calls_per_func', 'mean_cpf', 'median_cpf', 'afr', 'count_inline_asserts', 'iaf',
           'mean_iaf', 'median_iaf', 'calc_ifp', 'ifp', 'mcp', 'tcl', 'lint_nb', 'format_quality_warning',
           'get_excluded_paths', 'lint_nbs', 'calculate_warnings', 'scilint_lint', 'scilint_build', 'scilint_ci']

# %% ../nbs/scilint.ipynb 2
import ast
import os
import re
import shutil
import sys
import warnings
from collections import Counter
from pathlib import Path
from typing import Iterable

import nbformat
import numpy as np
import pandas as pd
from execnb.nbio import read_nb
from fastcore.script import call_parse
from nbdev.clean import nbdev_clean
from nbdev.config import add_init, get_config
from nbdev.doclinks import _build_modidx, nbdev_export, nbglob
from nbdev.export import nb_export
from nbdev.quarto import nbdev_docs, nbdev_readme
from nbdev.test import nbdev_test
from nbqa.__main__ import _get_configs, _main
from nbqa.cmdline import CLIArgs
from nbqa.find_root import find_project_root

# %% ../nbs/scilint.ipynb 7
def run_nbqa_cmd(cmd):
    print(f"Running {cmd}")
    project_root: Path = find_project_root(tuple([str(Path(".").resolve())]))
    args = CLIArgs.parse_args([cmd, str(project_root)])
    configs = _get_configs(args, project_root)
    output_code = _main(args, configs)
    return output_code

# %% ../nbs/scilint.ipynb 9
def tidy():
    tidy_tools = ["black", "isort", "autoflake"]
    [run_nbqa_cmd(c) for c in tidy_tools]

# %% ../nbs/scilint.ipynb 10
@call_parse
def scilint_tidy():
    tidy()

# %% ../nbs/scilint.ipynb 13
def get_func_defs(code, ignore_private_prefix=True):
    func_names = []
    for stmt in ast.walk(ast.parse(code)):
        if isinstance(stmt, ast.FunctionDef):
            inner_cond = (
                False if ignore_private_prefix and stmt.name.startswith("_") else True
            )
            if inner_cond:
                func_names.append(stmt.name)
    return func_names

# %% ../nbs/scilint.ipynb 15
def count_func_calls(code, func_defs):
    func_calls = Counter({k: 0 for k in func_defs})
    for stmt in ast.walk(ast.parse(code)):
        if isinstance(stmt, ast.Call):
            func_name = stmt.func.id if "id" in stmt.func.__dict__ else stmt.func.attr
            if func_name in func_defs:
                if func_name in func_calls:
                    func_calls[func_name] += 1
    return func_calls

# %% ../nbs/scilint.ipynb 19
def replace_ipython_magics(code):
    # Replace Ipython magic and shell command symbol with comment
    code = code.replace("%", "#")
    code = re.sub(r"^!", "#", code)
    return re.sub(r"\n\W?!", "\n#", code)

# %% ../nbs/scilint.ipynb 21
def safe_div(numer, denom):
    return 0 if denom == 0 else numer / denom

# %% ../nbs/scilint.ipynb 23
def get_cell_code(nb):
    pnb = nbformat.from_dict(nb)
    nb_cell_code = "\n".join(
        [
            replace_ipython_magics(c["source"])
            for c in pnb.cells
            if c["cell_type"] == "code"
        ]
    )
    return nb_cell_code

# %% ../nbs/scilint.ipynb 25
def calls_per_func(nb):
    nb_cell_code = get_cell_code(nb)
    func_defs = get_func_defs(nb_cell_code)
    func_calls = count_func_calls(nb_cell_code, func_defs)
    return func_calls

# %% ../nbs/scilint.ipynb 26
def mean_cpf(nb):
    return pd.Series(calls_per_func(nb)).mean()

# %% ../nbs/scilint.ipynb 27
def median_cpf(nb):
    return pd.Series(calls_per_func(nb)).median()

# %% ../nbs/scilint.ipynb 35
def afr(nb):
    nb_cell_code = get_cell_code(nb)
    if nb_cell_code == "":  # no code cells - metrics is not well defined
        return np.nan
    func_defs = get_func_defs(nb_cell_code)
    num_funcs = len(func_defs)

    assert_count = 0
    for stmt in ast.walk(ast.parse(nb_cell_code)):
        if isinstance(stmt, ast.Assert):
            assert_count += 1

    return safe_div(assert_count, num_funcs)

# %% ../nbs/scilint.ipynb 38
def count_inline_asserts(code, func_defs):
    inline_func_asserts = Counter({k: 0 for k in func_defs})

    for stmt in ast.walk(ast.parse(code)):
        if isinstance(stmt, ast.Assert):
            for assert_st in ast.walk(stmt):
                if isinstance(assert_st, ast.Call):
                    func_name = (
                        assert_st.func.id
                        if "id" in assert_st.func.__dict__
                        else assert_st.func.attr
                    )
                    if func_name in inline_func_asserts:
                        inline_func_asserts[func_name] += 1
    return inline_func_asserts

# %% ../nbs/scilint.ipynb 39
def iaf(nb):
    nb_cell_code = get_cell_code(nb)
    if nb_cell_code == "":
        return np.nan
    func_defs = get_func_defs(nb_cell_code)
    return count_inline_asserts(nb_cell_code, func_defs)

# %% ../nbs/scilint.ipynb 46
def mean_iaf(nb):
    return pd.Series(iaf(nb)).mean()

# %% ../nbs/scilint.ipynb 47
def median_iaf(nb):
    with warnings.catch_warnings():
        warnings.filterwarnings(action="ignore", message="Mean of empty slice")
        return pd.Series(iaf(nb)).median()

# %% ../nbs/scilint.ipynb 51
def calc_ifp(nb_cell_code):
    stmts_in_func = 0
    stmts_outside_func = 0
    for stmt in ast.walk(ast.parse(replace_ipython_magics(nb_cell_code))):
        if isinstance(stmt, ast.FunctionDef) and not stmt.name.startswith("_"):
            for body_item in stmt.body:
                stmts_in_func += 1
        elif isinstance(stmt, ast.Module):
            for body_item in stmt.body:
                if not isinstance(body_item, ast.FunctionDef):
                    stmts_outside_func += 1
    return (
        0
        if stmts_outside_func + stmts_in_func == 0
        else (stmts_in_func / (stmts_outside_func + stmts_in_func)) * 100
    )

# %% ../nbs/scilint.ipynb 53
def ifp(nb):
    nb_cell_code = "\n".join(
        [
            replace_ipython_magics(c["source"])
            for c in nb.cells
            if c["cell_type"] == "code"
        ]
    )
    if nb_cell_code == "":
        return np.nan
    return calc_ifp(nb_cell_code)

# %% ../nbs/scilint.ipynb 56
def mcp(nb):
    md_cells = [c for c in nb.cells if c["cell_type"] == "markdown"]
    code_cells = [c for c in nb.cells if c["cell_type"] == "code"]
    num_code_cells = len(code_cells)
    if num_code_cells == 0:
        return np.nan
    num_md_cells = len(md_cells)
    return (
        100
        if num_code_cells == 0
        else (num_md_cells / (num_md_cells + num_code_cells)) * 100
    )

# %% ../nbs/scilint.ipynb 59
def tcl(nb):
    return sum([len(c["source"]) for c in nb.cells if c["cell_type"] == "code"])

# %% ../nbs/scilint.ipynb 61
def lint_nb(
    nb_path,
    include_in_scoring,
    rounding_precision=3,
):
    nb = read_nb(nb_path)

    import warnings

    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=RuntimeWarning)
        nb_cpf_median = round(median_cpf(nb), rounding_precision)
        nb_cpf_mean = round(mean_cpf(nb), rounding_precision)
        nb_ifp = round(ifp(nb), rounding_precision)
        nb_afr = round(afr(nb), rounding_precision)
        nb_iaf_median = round(median_iaf(nb), rounding_precision)
    nb_iaf_mean = round(mean_iaf(nb), rounding_precision)
    nb_mcp = round(mcp(nb), rounding_precision)
    nb_tcl = round(tcl(nb), rounding_precision)

    return (
        nb_cpf_median,
        nb_cpf_mean,
        nb_ifp,
        nb_afr,
        nb_iaf_median,
        nb_iaf_mean,
        nb_mcp,
        nb_tcl,
        include_in_scoring,
    )

# %% ../nbs/scilint.ipynb 62
# TODO generate and persist a new dataframe of warnings from this..


def format_quality_warning(metric, warning_data, warn_thresh, direction):
    for warning_row in warning_data.reset_index().itertuples():
        print(f'"{warning_row.index}" has: {metric} {direction} {warn_thresh}')

# %% ../nbs/scilint.ipynb 63
def get_excluded_paths(paths: Iterable[Path], exclude_pattern: str):
    excl_paths = []
    for ex_pattern in exclude_pattern.split(","):
        ex_path = Path(ex_pattern)
        if ex_path.exists():
            excl_paths.extend([p for p in paths if ex_pattern in str(p)])
        elif not ex_path.exists():
            raise ValueError(f"Path component: {ex_path} does not exist")
        else:
            raise ValueError(
                f"Invalid exclusion pattern: {ex_path} pattern is comma separrated list of 'dir/' for directories and 'name.ipynb' for specific notebook"
            )
    return excl_paths

# %% ../nbs/scilint.ipynb 65
def lint_nbs(
    cpf_med_warn_thresh=1,
    cpf_mean_warn_thresh=1,
    ifp_warn_thresh=20,
    afr_warn_thresh=1,
    iaf_med_warn_thresh=0,
    iaf_mean_warn_thresh=0.5,
    mcp_warn_thresh=5,
    tcl_warn_thresh=30000,
    rounding_precision=3,
    csv_out_path="/tmp/scilint.csv",
    exclusions=None,
):
    nb_paths = [Path(p) for p in nbglob()]

    excluded_paths = None
    if exclusions is not None:
        excluded_paths = get_excluded_paths(nb_paths, exclude_pattern=exclusions)

    lt_metric_cols = [
        "cpf_median",
        "cpf_mean",
        "in_function_pct",
        "asserts_function_ratio",
        "iaf_median",
        "iaf_mean",
        "markdown_code_pct",
    ]
    gt_metric_cols = ["total_code_len"]
    lt_metrics_thresholds = [
        cpf_med_warn_thresh,
        cpf_mean_warn_thresh,
        ifp_warn_thresh,
        afr_warn_thresh,
        iaf_med_warn_thresh,
        iaf_mean_warn_thresh,
        mcp_warn_thresh,
    ]
    gt_metrics_thresholds = [tcl_warn_thresh]
    results = []
    nb_names = []
    for nb_path in nb_paths:
        include_in_scoring = True
        if exclusions is not None:
            include_in_scoring = False if nb_path in excluded_paths else True

        nb_names.append(nb_path.stem)
        results.append(lint_nb(nb_path, include_in_scoring, rounding_precision))
    lint_report = pd.DataFrame.from_records(
        data=results,
        index=nb_names,
        columns=lt_metric_cols + gt_metric_cols + ["include_in_scoring"],
    ).sort_values(["cpf_median", "markdown_code_pct"], ascending=False)

    # Calculate warnings only from notebooks included in scoring
    scoring_report = lint_report[lint_report.include_in_scoring].copy()

    num_warnings = calculate_warnings(
        scoring_report,
        lt_metric_cols,
        lt_metrics_thresholds,
        gt_metric_cols,
        gt_metrics_thresholds,
    )

    lint_report.to_csv(csv_out_path)

    return lint_report, num_warnings

# %% ../nbs/scilint.ipynb 66
def calculate_warnings(
    scoring_report,
    lt_metric_cols,
    lt_metrics_thresholds,
    gt_metric_cols,
    gt_metrics_thresholds,
):
    # TODO tidy this up to usual config dict
    print("\n*********************Begin Scilint Report*********************")
    issues_raised = False
    num_warnings = 0

    for lt_metric_col, lt_metrics_threshold in zip(
        lt_metric_cols, lt_metrics_thresholds
    ):
        metrics_series = scoring_report[lt_metric_col]
        warning_data = metrics_series[metrics_series < lt_metrics_threshold]

        num_warnings += len(warning_data)
        if num_warnings > 0:
            issues_raised = True
        format_quality_warning(
            lt_metric_col,
            warning_data,
            lt_metrics_threshold,
            direction="<",
        )
    for gt_metric_col, gt_metrics_threshold in zip(
        gt_metric_cols, gt_metrics_thresholds
    ):
        metrics_series = scoring_report[gt_metric_col]
        warning_data = metrics_series[metrics_series > gt_metrics_threshold]
        num_warnings += len(warning_data)
        if num_warnings > 0:
            issues_raised = True
        format_quality_warning(
            gt_metric_col,
            warning_data,
            gt_metrics_threshold,
            direction=">",
        )
    if not issues_raised:
        print("No issues found")
    print("*********************End Scilint Report***********************")
    return num_warnings

# %% ../nbs/scilint.ipynb 73
def _nbdev_lib_export():
    if os.environ.get("IN_TEST", 0):
        return
    files = nbglob(path=None, as_path=True).sorted("name")

    for f in files:
        nb_export(f, procs=None)
    add_init(get_config().lib_path)
    _build_modidx()

# %% ../nbs/scilint.ipynb 74
def _nbdev_lib_test(
    path=None,
    flags="",
    ignore_fname=".notest",
    n_workers: int = None,  # Number of workers
    timing: bool = False,  # Time each notebook to see which are slow
    do_print: bool = False,  # Print start and end of each notebook
    pause: float = 0.01,  # Pause time (in seconds) between notebooks to avoid race conditions
):
    "Test in parallel notebooks matching `path`, passing along `flags`"
    skip_flags = get_config().tst_flags.split()
    force_flags = flags.split()
    files = nbglob(path, as_path=True)
    from nbdev.test import _keep_file, test_nb

    files = [f.absolute() for f in sorted(files) if _keep_file(f, ignore_fname)]
    if len(files) == 0:
        return print("No files were eligible for testing")

    from fastcore.basics import IN_NOTEBOOK, num_cpus
    from fastcore.foundation import working_directory
    from fastcore.parallel import parallel

    if n_workers is None:
        n_workers = 0 if len(files) == 1 else min(num_cpus(), 8)
    if IN_NOTEBOOK:
        kw = {"method": "spawn"} if os.name == "nt" else {"method": "forkserver"}
    else:
        kw = {}
    wd_pth = get_config().nbs_path
    with working_directory(wd_pth if (wd_pth and wd_pth.exists()) else os.getcwd()):
        results = parallel(
            test_nb,
            files,
            skip_flags=skip_flags,
            force_flags=force_flags,
            n_workers=n_workers,
            basepath=get_config().config_path,
            pause=pause,
            do_print=do_print,
            **kw,
        )
    passed, times = zip(*results)
    if all(passed):
        print("Success.")
    else:
        _fence = "=" * 50
        failed = "\n\t".join(f.name for p, f in zip(passed, files) if not p)
        sys.stderr.write(
            f"\nnbdev Tests Failed On The Following Notebooks:\n{_fence}\n\t{failed}\n"
        )
        sys.exit(1)
    if timing:
        for i, t in sorted(enumerate(times), key=lambda o: o[1], reverse=True):
            print(f"{files[i].name}: {int(t)} secs")

# %% ../nbs/scilint.ipynb 75
def _nbdev_lib_clean():
    "Clean all notebooks in `fname` to avoid merge conflicts"
    # Git hooks will pass the notebooks in stdin
    from fastcore.basics import partial
    from fastcore.xtras import globtastic
    from nbdev.clean import _nbdev_clean, process_write

    _clean = partial(_nbdev_clean, clear_all=None)
    _write = partial(process_write, warn_msg="Failed to clean notebook", proc_nb=_clean)

    fname = get_config().nbs_path
    for f in globtastic(fname, file_glob="*.ipynb", skip_folder_re="^[_.]"):
        _write(f_in=f)

# %% ../nbs/scilint.ipynb 76
def _nbdev_lib_readme(
    path: str = None, chk_time: bool = False  # Path to notebooks
):  # Only build if out of date
    from nbdev.quarto import (
        _readme_mtime_not_older,
        _save_cached_readme,
        _SidebarYmlRemoved,
        _sprun,
    )
    from nbdev.serve import proc_nbs

    cfg = get_config()
    path = Path(path) if path else cfg.nbs_path
    if chk_time and _readme_mtime_not_older(
        cfg.config_path / "README.md", path / cfg.readme_nb
    ):
        return

    with _SidebarYmlRemoved(path):  # to avoid rendering whole website
        cache = proc_nbs(path)
        _sprun(
            f'cd "{cache}" && quarto render "{cache/cfg.readme_nb}" -o README.md -t gfm --no-execute'
        )

    _save_cached_readme(cache, cfg)

# %% ../nbs/scilint.ipynb 79
def _lint(
    cpf_med_warn_thresh: float = 1,
    cpf_mean_warn_thresh: float = 1,
    ifp_warn_thresh: float = 20,
    afr_warn_thresh: float = 1,
    iaf_med_warn_thresh: float = 0,
    iaf_mean_warn_thresh: float = 0.5,
    mcp_warn_thresh: float = 5,
    tcl_warn_thresh: float = 30000,
    rounding_precision: int = 3,
    csv_out_path: str = "/tmp/scilint.csv",
    exclusions: str = None,
    fail_over: int = 1,
):
    lint_report, num_warnings = lint_nbs(
        cpf_med_warn_thresh,
        cpf_mean_warn_thresh,
        ifp_warn_thresh,
        afr_warn_thresh,
        iaf_med_warn_thresh,
        iaf_mean_warn_thresh,
        mcp_warn_thresh,
        tcl_warn_thresh,
        rounding_precision,
        csv_out_path,
        exclusions,
    )
    if fail_over == -1:
        print("Linting outcome ignored as fail_over set to -1")
    elif num_warnings > fail_over:
        print(
            f"Linting failed: total warnings ({num_warnings}) exceeded threshold ({fail_over})"
        )
        sys.exit(num_warnings)
    else:
        print("Linting succeeded")

# %% ../nbs/scilint.ipynb 80
def _build(
    cpf_med_warn_thresh: float = 1,
    cpf_mean_warn_thresh: float = 1,
    ifp_warn_thresh: float = 20,
    afr_warn_thresh: float = 1,
    iaf_med_warn_thresh: float = 0,
    iaf_mean_warn_thresh: float = 0.5,
    mcp_warn_thresh: float = 5,
    tcl_warn_thresh: float = 30000,
    rounding_precision: int = 3,
    csv_out_path: str = "/tmp/scilint.csv",
    exclusions: str = None,
    fail_over: int = 1,
):
    tidy()
    nbdev_export.__wrapped__()
    nbdev_test.__wrapped__()
    _lint(
        cpf_med_warn_thresh,
        cpf_mean_warn_thresh,
        ifp_warn_thresh,
        afr_warn_thresh,
        iaf_med_warn_thresh,
        iaf_mean_warn_thresh,
        mcp_warn_thresh,
        tcl_warn_thresh,
        rounding_precision,
        csv_out_path,
        exclusions,
        fail_over,
    )
    nbdev_clean.__wrapped__()

# %% ../nbs/scilint.ipynb 82
@call_parse
def scilint_lint(
    cpf_med_warn_thresh: float = 1,
    cpf_mean_warn_thresh: float = 1,
    ifp_warn_thresh: float = 20,
    afr_warn_thresh: float = 1,
    iaf_med_warn_thresh: float = 0,
    iaf_mean_warn_thresh: float = 0.5,
    mcp_warn_thresh: float = 5,
    tcl_warn_thresh: float = 30000,
    rounding_precision: int = 3,
    csv_out_path: str = "/tmp/scilint.csv",
    exclusions: str = None,
    fail_over: int = 1,
):
    _lint(
        cpf_med_warn_thresh,
        cpf_mean_warn_thresh,
        ifp_warn_thresh,
        afr_warn_thresh,
        iaf_med_warn_thresh,
        iaf_mean_warn_thresh,
        mcp_warn_thresh,
        tcl_warn_thresh,
        rounding_precision,
        csv_out_path,
        exclusions,
        fail_over,
    )

# %% ../nbs/scilint.ipynb 83
@call_parse
def scilint_build(
    cpf_med_warn_thresh: float = 1,
    cpf_mean_warn_thresh: float = 1,
    ifp_warn_thresh: float = 20,
    afr_warn_thresh: float = 1,
    iaf_med_warn_thresh: float = 0,
    iaf_mean_warn_thresh: float = 0.5,
    mcp_warn_thresh: float = 5,
    tcl_warn_thresh: float = 30000,
    rounding_precision: int = 3,
    csv_out_path: str = "/tmp/scilint.csv",
    exclusions: str = None,
    fail_over: int = 1,
):
    _build(
        cpf_med_warn_thresh,
        cpf_mean_warn_thresh,
        ifp_warn_thresh,
        afr_warn_thresh,
        iaf_med_warn_thresh,
        iaf_mean_warn_thresh,
        mcp_warn_thresh,
        tcl_warn_thresh,
        rounding_precision,
        csv_out_path,
        exclusions,
        fail_over,
    )

# %% ../nbs/scilint.ipynb 84
@call_parse
def scilint_ci(
    cpf_med_warn_thresh: float = 1,
    cpf_mean_warn_thresh: float = 1,
    ifp_warn_thresh: float = 20,
    afr_warn_thresh: float = 1,
    iaf_med_warn_thresh: float = 0,
    iaf_mean_warn_thresh: float = 0.5,
    mcp_warn_thresh: float = 5,
    tcl_warn_thresh: int = 30000,
    rounding_precision: int = 3,
    csv_out_path: str = "/tmp/scilint.csv",
    exclusions: str = None,
    fail_over: int = 1,
):
    _build(
        cpf_med_warn_thresh,
        cpf_mean_warn_thresh,
        ifp_warn_thresh,
        afr_warn_thresh,
        iaf_med_warn_thresh,
        iaf_mean_warn_thresh,
        mcp_warn_thresh,
        tcl_warn_thresh,
        rounding_precision,
        csv_out_path,
        exclusions,
        fail_over,
    )
    if not shutil.which("quarto"):
        print(
            "Quarto is not installed. A working quarto install is required for the CI build"
        )
        sys.exit(-1)
    nbdev_readme.__wrapped__()
    nbdev_docs.__wrapped__()
