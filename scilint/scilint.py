# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/scilint.ipynb.

# %% auto 0
__all__ = ['run_nbqa_cmd', 'scilint_tidy', 'get_function_defs', 'count_func_calls', 'replace_ipython_magics', 'safe_div',
           'get_cell_code', 'calls_per_func', 'mean_cpf', 'median_cpf', 'count_inline_asserts', 'iaf', 'mean_iaf',
           'median_iaf', 'calc_ifp', 'ifp', 'mcp', 'tcl', 'lint_nb', 'format_quality_warning', 'lint_nbs',
           'sciflow_lint']

# %% ../nbs/scilint.ipynb 2
import ast
import os
import re
from collections import Counter
from pathlib import Path
import pandas as pd
import numpy as np

import nbformat
from fastcore.script import call_parse
from execnb.nbio import read_nb
from nbdev.doclinks import nbglob
from nbqa.__main__ import _get_configs, _main
from nbqa.cmdline import CLIArgs
from nbqa.find_root import find_project_root

# %% ../nbs/scilint.ipynb 7
def run_nbqa_cmd(cmd):
    print(f"Running {cmd}")
    project_root: Path = find_project_root(tuple([str(Path(".").resolve())]))
    args = CLIArgs.parse_args([cmd, str(project_root)])
    configs = _get_configs(args, project_root)
    output_code = _main(args, configs)
    return output_code

# %% ../nbs/scilint.ipynb 9
@call_parse
def scilint_tidy():
    """
    Run notebook formatting and tidy utilities.
    These tools should be configured to run automatically without intervention."
    """
    tidy_tools = ["black", "isort", "autoflake"]
    [run_nbqa_cmd(c) for c in tidy_tools]

# %% ../nbs/scilint.ipynb 12
def get_function_defs(code, ignore_private_prefix = True):
    
    func_names = []
    for stmt in ast.walk(ast.parse(code)):
        if isinstance(stmt, ast.FunctionDef):
            inner_cond = False if ignore_private_prefix and stmt.name.startswith("_") else True
            if inner_cond:
                func_names.append(stmt.name)
    return func_names

# %% ../nbs/scilint.ipynb 14
def count_func_calls(code, func_defs):
    func_calls = Counter({k: 0 for k in func_defs})
    for stmt in ast.walk(ast.parse(code)):
        if isinstance(stmt, ast.Call):
            func_name = stmt.func.id if "id" in stmt.func.__dict__ else stmt.func.attr
            if func_name in func_defs:
                if func_name in func_calls:
                    func_calls[func_name] += 1
    return func_calls

# %% ../nbs/scilint.ipynb 18
def replace_ipython_magics(code):
    # Replace Ipython magic and shell command symbol with comment
    code = code.replace("%", "#")
    code = re.sub(r"^!", "#", code)
    return re.sub(r"\n\W?!", "\n#", code)

# %% ../nbs/scilint.ipynb 20
def safe_div(numer, denom):
    return 0 if denom == 0 else numer / denom

# %% ../nbs/scilint.ipynb 22
def get_cell_code(nb):
    pnb = nbformat.from_dict(nb)
    nb_cell_code = "\n".join(
        [
            replace_ipython_magics(c["source"])
            for c in pnb.cells
            if c["cell_type"] == "code"
        ]
    )
    return nb_cell_code

# %% ../nbs/scilint.ipynb 23
def calls_per_func(nb):
    nb_cell_code = get_cell_code(nb)
    func_defs = get_function_defs(nb_cell_code)
    func_calls = count_func_calls(nb_cell_code, func_defs)
    return func_calls

# %% ../nbs/scilint.ipynb 24
def mean_cpf(nb):
    return pd.Series(calls_per_func(nb)).mean()

# %% ../nbs/scilint.ipynb 25
def median_cpf(nb):
    return pd.Series(calls_per_func(nb)).median()

# %% ../nbs/scilint.ipynb 38
def count_inline_asserts(code, func_defs):
    inline_func_asserts = Counter({k: 0 for k in func_defs})
    
    for stmt in ast.walk(ast.parse(code)):
        if isinstance(stmt, ast.Assert):
            for assert_st in ast.walk(stmt):
                if isinstance(assert_st, ast.Call):
                    func_name = assert_st.func.id if "id" in assert_st.func.__dict__ else assert_st.func.attr
                    if func_name in inline_func_asserts:
                        inline_func_asserts[func_name] += 1
    return inline_func_asserts

# %% ../nbs/scilint.ipynb 39
def iaf(nb):
    nb_cell_code = get_cell_code(nb)
    func_defs = get_function_defs(nb_cell_code)
    return count_inline_asserts(nb_cell_code, func_defs)

# %% ../nbs/scilint.ipynb 46
def mean_iaf(nb):
    return pd.Series(iaf(nb)).mean()

# %% ../nbs/scilint.ipynb 47
def median_iaf(nb):
    return pd.Series(iaf(nb)).median()

# %% ../nbs/scilint.ipynb 51
def calc_ifp(nb_cell_code):
    stmts_in_func = 0
    stmts_outside_func = 0
    for stmt in ast.walk(ast.parse(replace_ipython_magics(nb_cell_code))):
        if isinstance(stmt, ast.FunctionDef) and not stmt.name.startswith("_"):
            for body_item in stmt.body:
                stmts_in_func += 1
        elif isinstance(stmt, ast.Module):
            for body_item in stmt.body:
                if not isinstance(body_item, ast.FunctionDef):
                    stmts_outside_func += 1
    return (
        0
        if stmts_outside_func + stmts_in_func == 0
        else (stmts_in_func / (stmts_outside_func + stmts_in_func)) * 100
    )

# %% ../nbs/scilint.ipynb 53
def ifp(nb):
    nb_cell_code = "\n".join(
        [
            replace_ipython_magics(c["source"])
            for c in nb.cells
            if c["cell_type"] == "code"
        ]
    )
    return calc_ifp(nb_cell_code)

# %% ../nbs/scilint.ipynb 56
def mcp(nb):
    md_cells = [c for c in nb.cells if c["cell_type"] == "markdown"]
    code_cells = [c for c in nb.cells if c["cell_type"] == "code"]
    num_code_cells = len(code_cells)
    num_md_cells = len(md_cells)
    return (
        0
        if num_code_cells == 0
        else (num_md_cells / (num_md_cells + num_code_cells)) * 100
    )

# %% ../nbs/scilint.ipynb 59
def tcl(nb):
    return sum([len(c["source"]) for c in nb.cells if c["cell_type"] == "code"])

# %% ../nbs/scilint.ipynb 61
def lint_nb(
    nb_path,
    tpf_warn_thresh=None,
    ifp_warn_thresh=None,
    afr_warn_thresh=1,
    iaf_med_warn_thresh=0,
    iaf_mean_warn_thresh=0.5,
    mcp_warn_thresh=None,
    tcl_warn_thresh=None,
    rounding_precision=3,
):
    nb = read_nb(nb_path)
    result = (np.nan, np.nan, np.nan, np.nan)
    nb_cpf_median = round(median_cpf(nb), rounding_precision)
    nb_cpf_mean = round(mean_cpf(nb), rounding_precision)
    nb_ifp = round(ifp(nb), rounding_precision)
    nb_afr = round(afr(nb), rounding_precision)
    nb_iaf_median = round(median_iaf(nb), rounding_precision)
    nb_iaf_mean = round(mean_iaf(nb), rounding_precision)
    nb_mcp = round(mcp(nb), rounding_precision)
    nb_tcl = round(tcl(nb), rounding_precision)
    # print(f"NB: {nb_path.name} CallsPerFunction (Median): {nb_cpf_median} CallsPerFunction (Mean): {nb_cpf_mean} \
    # In-FunctionPercent: {nb_ifp} AssertsPerFunction: {nb_cpf_median} InlineAssertsPerFunction (Median): {nb_iaf_median} \
    # InlineAssertsPerFunction (Mean): {nb_iaf_mean} MarkdownToCodeRatio: {nb_mcp} TotalCodeLen: {nb_tcl}")
    return (nb_cpf_median, nb_cpf_mean, nb_ifp, nb_afr, nb_iaf_median, nb_iaf_mean, nb_mcp, nb_tcl)

# %% ../nbs/scilint.ipynb 62
def format_quality_warning(metric, warning_data, warn_thresh, direction):
    for warning_row in warning_data.reset_index().itertuples():
        print(f'"{warning_row.index}" has: {metric} {direction} {warn_thresh}')

# %% ../nbs/scilint.ipynb 63
def lint_nbs(
    cpf_med_warn_thresh=1,
    cpf_mean_warn_thresh=1,
    ifp_warn_thresh=20,
    afr_warn_thresh=1,
    iaf_med_warn_thresh=0,
    iaf_mean_warn_thresh=0.5,
    mcp_warn_thresh=5,
    tcl_warn_thresh=20000,
    rounding_precision=3,
):
    nb_paths = [Path(p) for p in nbglob()]
    lt_metric_cols = [
        "calls_per_function_median",
        "calls_per_function_mean",
        "in_function_pct",
        "asserts_function_ratio",
        "inline_asserts_per_function_median",
        "inline_asserts_per_function_mean",
        "markdown_code_pct",
    ]
    gt_metric_cols = ["total_code_len"]
    lt_metrics_thresholds = [cpf_med_warn_thresh, cpf_mean_warn_thresh, ifp_warn_thresh, afr_warn_thresh,
                             iaf_med_warn_thresh, iaf_mean_warn_thresh, mcp_warn_thresh]
    gt_metrics_thresholds = [tcl_warn_thresh]
    results = []
    nb_names = []
    for nb_path in nb_paths:
        nb_names.append(nb_path.stem)
        results.append(lint_nb(nb_path))
    lint_report = pd.DataFrame.from_records(
        data=results, index=nb_names, columns=lt_metric_cols + gt_metric_cols
    ).sort_values(["calls_per_function_median", "markdown_code_pct"], ascending=False)

    # TODO persist to remote storage
    # needs to be tied to a flow execution rather than a build
    # what is the best way to do this?

    print("\n*********************Begin Scilint Report*********************")
    issues_raised = False
    for lt_metric_col, lt_metrics_threshold in zip(
        lt_metric_cols, lt_metrics_thresholds
    ):
        metrics_series = lint_report[lt_metric_col]
        warning_data = metrics_series[metrics_series < lt_metrics_threshold]
        if len(warning_data) > 0:
            issues_raised = True
        format_quality_warning(
            lt_metric_col,
            warning_data,
            lt_metrics_threshold,
            direction="<",
        )
    for gt_metric_col, gt_metrics_threshold in zip(
        gt_metric_cols, gt_metrics_thresholds
    ):
        metrics_series = lint_report[gt_metric_col]
        warning_data = metrics_series[metrics_series > gt_metrics_threshold]
        if len(warning_data) > 0:
            issues_raised = True
        format_quality_warning(
            gt_metric_col,
            warning_data,
            gt_metrics_threshold,
            direction=">",
        )
    if not issues_raised:
        print("No issues found")
    print("*********************End Scilint Report***********************")

    return lint_report

# %% ../nbs/scilint.ipynb 66
@call_parse
def sciflow_lint():
    lint_nbs()
